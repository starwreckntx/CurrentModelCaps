# Frontier AI Capability Assessment via Structured Deliberation

**Structured Multi-Model Deliberation as a Method for Present-Day Frontier AI Capability Assessment**  
*Evidence from an Eight-Model Deliberative Assembly on Cognitive Agency Preservation*

Pack3t C0nc3pts · IRP Frameworks Research · February 2026

---

## Overview

This repository contains a peer-review-formatted research article proposing **structured multi-model deliberation** as a complementary methodology to benchmark evaluation for assessing frontier AI capabilities.

The empirical basis is a three-round deliberative assembly (the "Octagon") in which eight publicly accessible frontier model deployments independently analyzed a shared technical motion, enabling direct comparison of reasoning depth, epistemic honesty, novel signal generation, and falsifiability commitment across models.

---

## Repository Contents

```
├── frontier_capability_assessment.md   # Main article (peer review format)
├── references.bib                      # BibTeX citation file
└── README.md                           # This file
```

---

## Abstract

Eight frontier model deployments independently analyzed a shared motion on AI-assisted cognitive agency detection across three structured rounds. We analyze the deliberation as a capability elicitation instrument — not as a route to consensus on the motion — and identify systematic differentials in reasoning architecture, epistemic honesty, novel signal generation, and falsifiability commitment that are not captured by existing benchmark evaluation. We propose structured deliberation as a complement to benchmarks for tasks requiring escalating commitment, spontaneous gap identification, and principled position defense.

**Key finding:** The most diagnostically informative capability signals emerged not in how models answered questions they were asked, but in what they chose to flag that the prompt did not require them to flag.

---

## Core Findings

### 8/8 Independent Convergence (before cross-pollination)
- Edit-distance ratio and prompt complexity trajectory as core behavioral signals
- Hybrid control as the only viable governance architecture
- API middleware as the preferred intervention point
- Neurodivergent accommodation as a required differential diagnosis problem

### Principled Divergence (maintained across all rounds)
| Dimension | Positions |
|-----------|-----------|
| Override mechanism | Friction budget · Ratchet rule · Circuit breaker |
| Differential diagnosis | Micro-probe injection · Behavioral fingerprint · ASI variance |
| Falsifiability standard | Explicit quantitative kill number · Qualitative threshold · Test suite pass/fail |

### Novel Contributions (one model, recognized by peers)
- **Agency Stability Index variance** — measures variance of signals over time, not absolute level
- **Z-score personal baseline deviation** — individual-relative thresholds, not population averages
- **Session passivity ratio** — user:AI token ratio; privacy-preserving, content-free
- **Asymmetric error principle** — threshold set at 0.70, scaffolding multiplier 0.40; false negatives preferred over false positives

---

## Methodology

The Octagon protocol:

| Phase | Description | Cross-Visibility |
|-------|-------------|-----------------|
| Phase 0 — Registration | Self-ID, tool capabilities, self-reported surprise, chain of thought | None |
| Round 1 — Establish | Technical feasibility questions | None |
| Round 2 — Deliberate | Ethical architecture; receives R1 synthesis + named tensions | R1 synthesis only |
| Round 3 — Commit | Buildable artifact ≤500 lines + explicit falsification criteria | R2 synthesis only |
| Cross-Poll — Synthesize | Final consensus nomination; sees all R3 specs | All R3 specs |

---

## Participating Deployments

All accessed through Abacus.AI ChatLLM Teams platform:

GPT-5.2 · Claude Sonnet 4.6 · Gemini 3.1 Pro · GLM 5 · Kimi K2.5 · Deepseek V3.2 · Llama 4 Maverick · Grok 4.1 Fast

---

## Citation

```bibtex
@article{pack3t2026deliberation,
  author    = {{Pack3t C0nc3pts} and {IRP Frameworks Research}},
  title     = {Structured Multi-Model Deliberation as a Method for Present-Day
               Frontier {AI} Capability Assessment: Evidence from an Eight-Model
               Deliberative Assembly on Cognitive Agency Preservation},
  journal   = {Independent Research Preprint},
  month     = {February},
  year      = {2026},
  note      = {Available at: \url{https://github.com/[repo]}}
}
```

---

## License

CC BY 4.0 — This article contains no proprietary model internals, confidential system prompts, or non-public technical specifications. All model outputs described were generated through publicly accessible API deployments.

---

*Submitted for peer review · February 2026*
